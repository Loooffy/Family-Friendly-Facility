#!/usr/bin/env python3
"""
ä½¿ç”¨ ArcGIS Geocoding API ç‚ºå…¨åœ‹å“ºé›†ä¹³å®¤è³‡æ–™è£œé½Šç¶“ç·¯åº¦åº§æ¨™
ä½¿ç”¨å¹³è¡ŒåŒ–è™•ç†ä»¥åŠ é€Ÿè™•ç†
"""
import json
import urllib.parse
from pathlib import Path
from concurrent.futures import ThreadPoolExecutor, as_completed
from typing import Dict, List, Optional, Tuple
import requests
import time


# ArcGIS Geocoding API ç«¯é»
GEOCODE_API_URL = (
    "https://geocode.arcgis.com/arcgis/rest/services/World/GeocodeServer/findAddressCandidates"
)


def geocode_address(address: str) -> Optional[Tuple[float, float]]:
    """
    ä½¿ç”¨ ArcGIS API å°‡åœ°å€è½‰æ›ç‚ºç¶“ç·¯åº¦åº§æ¨™

    Args:
        address: åœ°å€å­—ä¸²

    Returns:
        åŒ…å« (longitude, latitude) çš„ tupleï¼Œå¦‚æœå¤±æ•—å‰‡è¿”å› None
    """
    if not address or not address.strip():
        return None

    try:
        # æº–å‚™ API è«‹æ±‚åƒæ•¸
        params = {
            "SingleLine": address,
            "f": "json",
            "outSR": '{"wkid":4326}',
            "outFields": "Addr_type,Match_addr,StAddr,City",
            "maxLocations": 6,
        }

        # ç™¼é€è«‹æ±‚
        response = requests.get(GEOCODE_API_URL, params=params, timeout=10)
        response.raise_for_status()

        data = response.json()

        # æª¢æŸ¥æ˜¯å¦æœ‰å€™é¸çµæœ
        if "candidates" not in data or not data["candidates"]:
            return None

        # æ‰¾å‡ºåˆ†æ•¸æœ€é«˜çš„å€™é¸é …ç›®
        best_candidate = max(data["candidates"], key=lambda x: x.get("score", 0))

        # æå–ç¶“ç·¯åº¦ï¼ˆæ³¨æ„ï¼šArcGIS ä½¿ç”¨ x=longitude, y=latitudeï¼‰
        location = best_candidate.get("location", {})
        longitude = location.get("x")
        latitude = location.get("y")

        if longitude is not None and latitude is not None:
            return (longitude, latitude)

        return None

    except requests.exceptions.RequestException as e:
        print(f"  âš  API è«‹æ±‚éŒ¯èª¤ ({address[:30]}...): {e}")
        return None
    except (KeyError, ValueError, TypeError) as e:
        print(f"  âš  è§£æéŒ¯èª¤ ({address[:30]}...): {e}")
        return None
    except Exception as e:
        print(f"  âš  æœªçŸ¥éŒ¯èª¤ ({address[:30]}...): {e}")
        return None


def process_item(
    item: Dict, index: int, total: int
) -> Tuple[int, Dict, Optional[Tuple[float, float]]]:
    """
    è™•ç†å–®ä¸€é …ç›®ï¼Œç²å–ç¶“ç·¯åº¦

    Args:
        item: è³‡æ–™é …ç›®
        index: é …ç›®ç´¢å¼•
        total: ç¸½é …ç›®æ•¸

    Returns:
        (index, item, coordinates) çš„ tuple
    """
    address = item.get("address", "")

    # å¦‚æœå·²ç¶“æœ‰ç¶“ç·¯åº¦ï¼Œè·³é
    if item.get("latitude") is not None and item.get("longitude") is not None:
        return (index, item, None)

    # ç²å–ç¶“ç·¯åº¦
    coordinates = geocode_address(address)

    if coordinates:
        longitude, latitude = coordinates
        item["longitude"] = longitude
        item["latitude"] = latitude
        print(
            f"  [{index+1}/{total}] âœ“ {item.get('name', '')[:30]}... -> ({latitude:.6f}, {longitude:.6f})"
        )
    else:
        print(f"  [{index+1}/{total}] âœ— {item.get('name', '')[:30]}... -> ç„¡æ³•å–å¾—åº§æ¨™")

    return (index, item, coordinates)


def geocode_nursing_rooms(
    input_file: Path, max_workers: int = 10, batch_size: int = 100, save_interval: int = 50
) -> None:
    """
    ç‚ºå“ºé›†ä¹³å®¤è³‡æ–™è£œé½Šç¶“ç·¯åº¦åº§æ¨™

    Args:
        input_file: è¼¸å…¥ JSON æª”æ¡ˆè·¯å¾‘
        max_workers: å¹³è¡Œè™•ç†çš„æœ€å¤§åŸ·è¡Œç·’æ•¸
        batch_size: æ¯æ‰¹è™•ç†çš„é …ç›®æ•¸ï¼ˆç”¨æ–¼é€²åº¦é¡¯ç¤ºï¼‰
        save_interval: æ¯è™•ç†å¤šå°‘é …ç›®å°±è‡ªå‹•å„²å­˜ä¸€æ¬¡ï¼ˆé¿å…ä¸­æ–·éºå¤±é€²åº¦ï¼‰
    """
    print(f"è®€å–æª”æ¡ˆï¼š{input_file}")

    # è®€å– JSON æª”æ¡ˆ
    with open(input_file, "r", encoding="utf-8") as f:
        data = json.load(f)

    items = data.get("data", [])
    total_count = len(items)

    # æ‰¾å‡ºéœ€è¦è™•ç†çš„é …ç›®ï¼ˆç¼ºå°‘ç¶“ç·¯åº¦çš„ï¼‰
    items_to_process = [
        (i, item)
        for i, item in enumerate(items)
        if item.get("latitude") is None or item.get("longitude") is None
    ]

    missing_count = len(items_to_process)
    print(f"\nç¸½é …ç›®æ•¸ï¼š{total_count}")
    print(f"ç¼ºå°‘ç¶“ç·¯åº¦çš„é …ç›®ï¼š{missing_count}")

    if missing_count == 0:
        print("âœ“ æ‰€æœ‰é …ç›®éƒ½å·²æœ‰ç¶“ç·¯åº¦åº§æ¨™ï¼Œç„¡éœ€è™•ç†")
        return

    print(f"\né–‹å§‹ä½¿ç”¨ {max_workers} å€‹åŸ·è¡Œç·’é€²è¡Œå¹³è¡Œè™•ç†...")
    print(f"æ¯è™•ç† {save_interval} å€‹é …ç›®æœƒè‡ªå‹•å„²å­˜ä¸€æ¬¡ï¼Œé¿å…ä¸­æ–·éºå¤±é€²åº¦")
    print("-" * 80)

    # ä½¿ç”¨ ThreadPoolExecutor é€²è¡Œå¹³è¡Œè™•ç†
    start_time = time.time()
    processed_count = 0
    success_count = 0
    last_save_count = 0

    # å»ºç«‹çµæœå­—å…¸ä¾†è¿½è¹¤å·²æ›´æ–°çš„é …ç›®
    updated_items = {}

    try:
        with ThreadPoolExecutor(max_workers=max_workers) as executor:
            # æäº¤æ‰€æœ‰ä»»å‹™
            future_to_item = {
                executor.submit(process_item, item, index, missing_count): (index, item)
                for index, item in items_to_process
            }

            # è™•ç†å®Œæˆçš„ä»»å‹™
            for future in as_completed(future_to_item):
                index, updated_item, coordinates = future.result()
                processed_count += 1

                # æ›´æ–°åŸå§‹è³‡æ–™
                items[index] = updated_item
                updated_items[index] = updated_item

                if coordinates:
                    success_count += 1

                # å®šæœŸå„²å­˜é€²åº¦
                if processed_count - last_save_count >= save_interval:
                    data["total_count"] = len(items)
                    with open(input_file, "w", encoding="utf-8") as f:
                        json.dump(data, f, ensure_ascii=False, indent=2)
                    last_save_count = processed_count
                    print(f"\nğŸ’¾ å·²è‡ªå‹•å„²å­˜é€²åº¦ï¼ˆ{processed_count}/{missing_count}ï¼‰\n")

                # æ¯è™•ç† batch_size å€‹é …ç›®å°±é¡¯ç¤ºé€²åº¦
                if processed_count % batch_size == 0:
                    elapsed = time.time() - start_time
                    rate = processed_count / elapsed if elapsed > 0 else 0
                    remaining = (missing_count - processed_count) / rate if rate > 0 else 0
                    print(
                        f"\né€²åº¦ï¼š{processed_count}/{missing_count} ({processed_count*100//missing_count}%) | "
                        f"æˆåŠŸï¼š{success_count} | é€Ÿç‡ï¼š{rate:.1f} é …/ç§’ | "
                        f"é ä¼°å‰©é¤˜æ™‚é–“ï¼š{remaining:.0f} ç§’\n"
                    )

    except KeyboardInterrupt:
        print("\n\nâš  è™•ç†è¢«ä¸­æ–·ï¼Œæ­£åœ¨å„²å­˜å·²è™•ç†çš„çµæœ...")
        data["total_count"] = len(items)
        with open(input_file, "w", encoding="utf-8") as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
        print(f"âœ“ å·²å„²å­˜ {processed_count} ç­†å·²è™•ç†çš„çµæœ")
        print("æ‚¨å¯ä»¥é‡æ–°åŸ·è¡Œè…³æœ¬ç¹¼çºŒè™•ç†å‰©é¤˜é …ç›®")
        return

    elapsed_time = time.time() - start_time

    print("-" * 80)
    print(f"\nè™•ç†å®Œæˆï¼")
    print(f"  ç¸½è™•ç†æ™‚é–“ï¼š{elapsed_time:.1f} ç§’")
    print(f"  è™•ç†é …ç›®æ•¸ï¼š{processed_count}")
    print(f"  æˆåŠŸå–å¾—åº§æ¨™ï¼š{success_count}")
    print(f"  å¤±æ•—é …ç›®æ•¸ï¼š{processed_count - success_count}")
    print(f"  å¹³å‡é€Ÿç‡ï¼š{processed_count/elapsed_time:.1f} é …/ç§’")

    # æ›´æ–° total_countï¼ˆä»¥é˜²æœ‰è®Šå‹•ï¼‰
    data["total_count"] = len(items)

    # æœ€çµ‚å„²å­˜
    print(f"\nå„²å­˜æ›´æ–°å¾Œçš„æª”æ¡ˆï¼š{input_file}")
    with open(input_file, "w", encoding="utf-8") as f:
        json.dump(data, f, ensure_ascii=False, indent=2)

    print("âœ“ æª”æ¡ˆå·²å„²å­˜")


if __name__ == "__main__":
    # è¨­å®šæª”æ¡ˆè·¯å¾‘
    base_dir = Path(__file__).parent
    input_file = base_dir / "cleaned_data" / "å…¨åœ‹å“ºé›†ä¹³å®¤.json"

    # åŸ·è¡Œ geocoding
    # max_workers: å¹³è¡Œè™•ç†çš„åŸ·è¡Œç·’æ•¸ï¼ˆå»ºè­° 10-20ï¼Œé¿å…éåº¦è«‹æ±‚ APIï¼‰
    geocode_nursing_rooms(input_file=input_file, max_workers=10, batch_size=50)
